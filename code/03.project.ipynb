{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# With missforest we can use random forest to impute data. This is better than mean by far\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "from pandas_profiling import ProfileReport\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1459\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing columns with a high ratio of NAs\n",
    "def remove_high_nan(df, ratio = 0.65):\n",
    "    for i in df.columns:\n",
    "        if df[i].isnull().mean() > ratio:\n",
    "            df.drop(i,axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "remove_high_nan(data)\n",
    "data_2 = data.copy()\n",
    "data.isnull().sum().plot(kind = 'bar', fontsize = 12, figsize = (12,4))\n",
    "plt. title('Null values we Have to handle', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# I need to get an example with real data.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Make an instance and perform the imputation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m imputer \u001b[38;5;241m=\u001b[39m MissForest()\n\u001b[0;32m----> 5\u001b[0m train_df_imputed \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(train_df)\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/missingpy/missforest.py:556\u001b[0m, in \u001b[0;36mMissForest.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    543\u001b[0m     \u001b[39m\"\"\"Fit MissForest and impute all missing values in X.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[1;32m    545\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39m        Returns imputed dataset.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/missingpy/missforest.py:440\u001b[0m, in \u001b[0;36mMissForest.fit\u001b[0;34m(self, X, y, cat_vars)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m# Check data integrity and calling arguments\u001b[39;00m\n\u001b[1;32m    437\u001b[0m force_all_finite \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing_values \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mNaN\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    438\u001b[0m                                                     np\u001b[39m.\u001b[39mnan] \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    441\u001b[0m                 force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Check for +/- inf\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(X)):\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "# I need to get an example with real data.\n",
    "\n",
    "# Make an instance and perform the imputation\n",
    "imputer = MissForest()\n",
    "train_df_imputed = imputer.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RL'"
     ]
    }
   ],
   "source": [
    "train_df['RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "#dropping NA to avoid issues with lgb fit.\n",
    "train_df['SalePrice'].dropna(inplace = True)\n",
    "\n",
    "print(len(train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting ready x and y variables\n",
    "x = train_df.drop(['Id','SalePrice'],axis=1)\n",
    "y = train_df.SalePrice\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectorcozar/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "x, y = boston.data, boston.target\n",
    "x_df = pd.DataFrame(x, columns= boston.feature_names)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y, test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters \n",
    "params = {\n",
    "    'task': 'train', \n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 10,\n",
    "    'learnnig_rage': 0.05,\n",
    "    'metric': {'l2','l1'},\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding data\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hectorcozar/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l2: 89.8079\tvalid_0's l1: 6.71541\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's l2: 77.5728\tvalid_0's l1: 6.20691\n",
      "[3]\tvalid_0's l2: 67.529\tvalid_0's l1: 5.74798\n",
      "[4]\tvalid_0's l2: 59.2784\tvalid_0's l1: 5.3473\n",
      "[5]\tvalid_0's l2: 52.3859\tvalid_0's l1: 4.98802\n",
      "[6]\tvalid_0's l2: 46.6775\tvalid_0's l1: 4.67455\n",
      "[7]\tvalid_0's l2: 42.038\tvalid_0's l1: 4.4116\n",
      "[8]\tvalid_0's l2: 37.9651\tvalid_0's l1: 4.17738\n",
      "[9]\tvalid_0's l2: 34.9744\tvalid_0's l1: 3.98992\n",
      "[10]\tvalid_0's l2: 32.0874\tvalid_0's l1: 3.82012\n",
      "[11]\tvalid_0's l2: 29.7616\tvalid_0's l1: 3.66791\n",
      "[12]\tvalid_0's l2: 27.5808\tvalid_0's l1: 3.54418\n",
      "[13]\tvalid_0's l2: 25.6489\tvalid_0's l1: 3.39711\n",
      "[14]\tvalid_0's l2: 24.1938\tvalid_0's l1: 3.30084\n",
      "[15]\tvalid_0's l2: 22.8786\tvalid_0's l1: 3.22715\n",
      "[16]\tvalid_0's l2: 21.6985\tvalid_0's l1: 3.13521\n",
      "[17]\tvalid_0's l2: 20.7678\tvalid_0's l1: 3.07105\n",
      "[18]\tvalid_0's l2: 19.7471\tvalid_0's l1: 2.98498\n",
      "[19]\tvalid_0's l2: 18.974\tvalid_0's l1: 2.9351\n",
      "[20]\tvalid_0's l2: 18.3259\tvalid_0's l1: 2.8747\n",
      "[21]\tvalid_0's l2: 17.6422\tvalid_0's l1: 2.79702\n",
      "[22]\tvalid_0's l2: 17.1861\tvalid_0's l1: 2.75658\n",
      "[23]\tvalid_0's l2: 16.7117\tvalid_0's l1: 2.72229\n",
      "[24]\tvalid_0's l2: 16.2778\tvalid_0's l1: 2.67792\n",
      "[25]\tvalid_0's l2: 16.0116\tvalid_0's l1: 2.64522\n",
      "[26]\tvalid_0's l2: 15.6194\tvalid_0's l1: 2.61772\n",
      "[27]\tvalid_0's l2: 15.2651\tvalid_0's l1: 2.5889\n",
      "[28]\tvalid_0's l2: 14.8763\tvalid_0's l1: 2.55463\n",
      "[29]\tvalid_0's l2: 14.547\tvalid_0's l1: 2.52742\n",
      "[30]\tvalid_0's l2: 14.2209\tvalid_0's l1: 2.50226\n",
      "[31]\tvalid_0's l2: 13.9782\tvalid_0's l1: 2.47342\n",
      "[32]\tvalid_0's l2: 13.7341\tvalid_0's l1: 2.45195\n",
      "[33]\tvalid_0's l2: 13.4744\tvalid_0's l1: 2.42257\n",
      "[34]\tvalid_0's l2: 13.2784\tvalid_0's l1: 2.40383\n",
      "[35]\tvalid_0's l2: 12.9221\tvalid_0's l1: 2.36873\n",
      "[36]\tvalid_0's l2: 12.8634\tvalid_0's l1: 2.36219\n",
      "[37]\tvalid_0's l2: 12.7452\tvalid_0's l1: 2.34993\n",
      "[38]\tvalid_0's l2: 12.5144\tvalid_0's l1: 2.32533\n",
      "[39]\tvalid_0's l2: 12.4553\tvalid_0's l1: 2.32184\n",
      "[40]\tvalid_0's l2: 12.2708\tvalid_0's l1: 2.3005\n",
      "[41]\tvalid_0's l2: 12.1608\tvalid_0's l1: 2.28216\n",
      "[42]\tvalid_0's l2: 12.1396\tvalid_0's l1: 2.2695\n",
      "[43]\tvalid_0's l2: 12.0642\tvalid_0's l1: 2.26958\n",
      "[44]\tvalid_0's l2: 12.0123\tvalid_0's l1: 2.26238\n",
      "[45]\tvalid_0's l2: 11.8375\tvalid_0's l1: 2.24132\n",
      "[46]\tvalid_0's l2: 11.8528\tvalid_0's l1: 2.23885\n",
      "[47]\tvalid_0's l2: 11.7014\tvalid_0's l1: 2.23161\n",
      "[48]\tvalid_0's l2: 11.7339\tvalid_0's l1: 2.23356\n",
      "[49]\tvalid_0's l2: 11.7589\tvalid_0's l1: 2.24111\n",
      "[50]\tvalid_0's l2: 11.6159\tvalid_0's l1: 2.22902\n",
      "[51]\tvalid_0's l2: 11.4381\tvalid_0's l1: 2.213\n",
      "[52]\tvalid_0's l2: 11.2599\tvalid_0's l1: 2.19176\n",
      "[53]\tvalid_0's l2: 11.2066\tvalid_0's l1: 2.19302\n",
      "[54]\tvalid_0's l2: 11.0694\tvalid_0's l1: 2.18184\n",
      "[55]\tvalid_0's l2: 10.9723\tvalid_0's l1: 2.17866\n",
      "[56]\tvalid_0's l2: 10.9924\tvalid_0's l1: 2.18573\n",
      "[57]\tvalid_0's l2: 10.8889\tvalid_0's l1: 2.17989\n",
      "[58]\tvalid_0's l2: 10.8175\tvalid_0's l1: 2.18066\n",
      "[59]\tvalid_0's l2: 10.7392\tvalid_0's l1: 2.17645\n",
      "[60]\tvalid_0's l2: 10.7009\tvalid_0's l1: 2.17118\n",
      "[61]\tvalid_0's l2: 10.6482\tvalid_0's l1: 2.17935\n",
      "[62]\tvalid_0's l2: 10.6014\tvalid_0's l1: 2.17489\n",
      "[63]\tvalid_0's l2: 10.4778\tvalid_0's l1: 2.16206\n",
      "[64]\tvalid_0's l2: 10.4112\tvalid_0's l1: 2.15783\n",
      "[65]\tvalid_0's l2: 10.4374\tvalid_0's l1: 2.1588\n",
      "[66]\tvalid_0's l2: 10.3716\tvalid_0's l1: 2.15849\n",
      "[67]\tvalid_0's l2: 10.2622\tvalid_0's l1: 2.15816\n",
      "[68]\tvalid_0's l2: 10.2412\tvalid_0's l1: 2.16161\n",
      "[69]\tvalid_0's l2: 10.2277\tvalid_0's l1: 2.15769\n",
      "[70]\tvalid_0's l2: 10.2011\tvalid_0's l1: 2.16311\n",
      "[71]\tvalid_0's l2: 10.1658\tvalid_0's l1: 2.16186\n",
      "[72]\tvalid_0's l2: 10.211\tvalid_0's l1: 2.16321\n",
      "[73]\tvalid_0's l2: 10.1556\tvalid_0's l1: 2.15931\n",
      "[74]\tvalid_0's l2: 10.171\tvalid_0's l1: 2.16416\n",
      "[75]\tvalid_0's l2: 10.1261\tvalid_0's l1: 2.15904\n",
      "[76]\tvalid_0's l2: 10.0645\tvalid_0's l1: 2.14743\n",
      "[77]\tvalid_0's l2: 10.049\tvalid_0's l1: 2.15305\n",
      "[78]\tvalid_0's l2: 10.0142\tvalid_0's l1: 2.14558\n",
      "[79]\tvalid_0's l2: 10.0388\tvalid_0's l1: 2.15175\n",
      "[80]\tvalid_0's l2: 9.98248\tvalid_0's l1: 2.14465\n",
      "[81]\tvalid_0's l2: 9.99543\tvalid_0's l1: 2.15115\n",
      "[82]\tvalid_0's l2: 9.96987\tvalid_0's l1: 2.15111\n",
      "[83]\tvalid_0's l2: 9.91279\tvalid_0's l1: 2.15468\n",
      "[84]\tvalid_0's l2: 9.90021\tvalid_0's l1: 2.15724\n",
      "[85]\tvalid_0's l2: 9.86142\tvalid_0's l1: 2.15435\n",
      "[86]\tvalid_0's l2: 9.8441\tvalid_0's l1: 2.15653\n",
      "[87]\tvalid_0's l2: 9.84263\tvalid_0's l1: 2.15307\n",
      "[88]\tvalid_0's l2: 9.83388\tvalid_0's l1: 2.15051\n",
      "[89]\tvalid_0's l2: 9.82822\tvalid_0's l1: 2.15342\n",
      "[90]\tvalid_0's l2: 9.77821\tvalid_0's l1: 2.1549\n",
      "[91]\tvalid_0's l2: 9.70666\tvalid_0's l1: 2.14867\n",
      "[92]\tvalid_0's l2: 9.70966\tvalid_0's l1: 2.14682\n",
      "[93]\tvalid_0's l2: 9.68513\tvalid_0's l1: 2.14822\n",
      "[94]\tvalid_0's l2: 9.66801\tvalid_0's l1: 2.14684\n",
      "[95]\tvalid_0's l2: 9.66462\tvalid_0's l1: 2.14775\n",
      "[96]\tvalid_0's l2: 9.62834\tvalid_0's l1: 2.14596\n",
      "[97]\tvalid_0's l2: 9.68727\tvalid_0's l1: 2.14888\n",
      "[98]\tvalid_0's l2: 9.68271\tvalid_0's l1: 2.14953\n",
      "[99]\tvalid_0's l2: 9.69185\tvalid_0's l1: 2.14806\n",
      "[100]\tvalid_0's l2: 9.67278\tvalid_0's l1: 2.14676\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\tvalid_0's l2: 9.62834\tvalid_0's l1: 2.14596\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# accuracy check\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[1;32m      6\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mse\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m mse)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# accuracy check\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**(0.5)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "print(\"RMSE: %.2f\" % rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [34900, 52500, 55993, 64500, 68500, 72500, 73000, 75500, 80500, 83500, 84000, 84900, 85000, 89000, 89471, 91300, 94500, 101800, 103200, 108500, 109000, 116900, 117000, 118858, 121500, 128200, 128950, 131400, 134450, 135960, 139400, 139900, 142953, 143750, 145250, 145900, 147400, 147500, 149350, 151400, 154300, 155835, 155900, 156500, 158500, 159895, 162500, 164700, 164900, 165150, 165400, 167240, 167900, 169990, 171500, 174500, 174900, 178400, 178900, 179540, 183500, 184750, 186500, 198900, 200100, 200500, 204900, 205950, 206900, 207000, 209500, 212900, 213250, 213490, 214500, 216000, 216500, 216837, 223000, 226700, 227680, 230500, 232600, 243000, 244400, 245000, 250580, 252000, 254900, 255500, 256300, 260400, 262280, 264132, 269500, 274000, 274300, 274725, 274970, 276000, 277500, 281000, 294000, 295000, 295493, 299800, 303477, 305900, 307000, 309000, 311872, 312500, 314813, 318000, 319900, 325624, 326000, 328900, 336000, 337000, 341000, 345000, 354000, 361919, 369900, 372500, 377500, 383970, 392000, 392500, 394617, 403000, 415298, 430000, 437154, 440000, 446261, 451950, 465000, 466500, 475000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#setting up the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.09\u001b[39m, max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, eval_set \u001b[38;5;241m=\u001b[39m [(x_test, y_test), (x_train, y_train)],\n\u001b[1;32m      4\u001b[0m           verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/lightgbm/sklearn.py:965\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    963\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, _y)\n\u001b[1;32m    964\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_le\u001b[39m.\u001b[39;49mtransform(valid_y))\n\u001b[1;32m    967\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, _y, sample_weight\u001b[39m=\u001b[39msample_weight, init_score\u001b[39m=\u001b[39minit_score, eval_set\u001b[39m=\u001b[39mvalid_sets,\n\u001b[1;32m    968\u001b[0m             eval_names\u001b[39m=\u001b[39meval_names, eval_sample_weight\u001b[39m=\u001b[39meval_sample_weight,\n\u001b[1;32m    969\u001b[0m             eval_class_weight\u001b[39m=\u001b[39meval_class_weight, eval_init_score\u001b[39m=\u001b[39meval_init_score,\n\u001b[1;32m    970\u001b[0m             eval_metric\u001b[39m=\u001b[39meval_metric, early_stopping_rounds\u001b[39m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m    971\u001b[0m             verbose\u001b[39m=\u001b[39mverbose, feature_name\u001b[39m=\u001b[39mfeature_name, categorical_feature\u001b[39m=\u001b[39mcategorical_feature,\n\u001b[1;32m    972\u001b[0m             callbacks\u001b[39m=\u001b[39mcallbacks, init_model\u001b[39m=\u001b[39minit_model)\n\u001b[1;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:138\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[0;32m~/Documents/GitHub/house_prizes_kaggle_python/venv/lib/python3.9/site-packages/sklearn/utils/_encode.py:231\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    229\u001b[0m     diff \u001b[39m=\u001b[39m _check_unknown(values, uniques)\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m diff:\n\u001b[0;32m--> 231\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(diff)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msearchsorted(uniques, values)\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [34900, 52500, 55993, 64500, 68500, 72500, 73000, 75500, 80500, 83500, 84000, 84900, 85000, 89000, 89471, 91300, 94500, 101800, 103200, 108500, 109000, 116900, 117000, 118858, 121500, 128200, 128950, 131400, 134450, 135960, 139400, 139900, 142953, 143750, 145250, 145900, 147400, 147500, 149350, 151400, 154300, 155835, 155900, 156500, 158500, 159895, 162500, 164700, 164900, 165150, 165400, 167240, 167900, 169990, 171500, 174500, 174900, 178400, 178900, 179540, 183500, 184750, 186500, 198900, 200100, 200500, 204900, 205950, 206900, 207000, 209500, 212900, 213250, 213490, 214500, 216000, 216500, 216837, 223000, 226700, 227680, 230500, 232600, 243000, 244400, 245000, 250580, 252000, 254900, 255500, 256300, 260400, 262280, 264132, 269500, 274000, 274300, 274725, 274970, 276000, 277500, 281000, 294000, 295000, 295493, 299800, 303477, 305900, 307000, 309000, 311872, 312500, 314813, 318000, 319900, 325624, 326000, 328900, 336000, 337000, 341000, 345000, 354000, 361919, 369900, 372500, 377500, 383970, 392000, 392500, 394617, 403000, 415298, 430000, 437154, 440000, 446261, 451950, 465000, 466500, 475000]"
     ]
    }
   ],
   "source": [
    "#setting up the model\n",
    "model = lgb.LGBMClassifier(learning_rate = 0.09, max_depth = -5, random_state = 42)\n",
    "model.fit(x_train, y_train, eval_set = [(x_test, y_test), (x_train, y_train)],\n",
    "          verbose = 20, eval_metric = 'logloss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "print('Training accuracy {:.4f}'.format(model.score(x_train,y_train)))\n",
    "print('Testing accuracy {:.4f}'.format(model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevant variables\n",
    "lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve of the model\n",
    "lgb.plot_metric(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tree of the model\n",
    "lgb.plot_tree(model,figsize=(30,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "metrics.plot_confusion_matrix(model,x_test,y_test,cmap='Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "print(metrics.classification_report(y_test,model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and getting data out from h2o\n",
    "predictions = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging predictions with the full data set\n",
    "submission = pd.merge(test_df['Id'],\n",
    "                          predictions,\n",
    "                          left_index = True,\n",
    "                          right_index = True)\n",
    "submission.rename(columns = {'predict': 'SalePrice'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "submission.to_csv('../data/submission_' + best_model_name + '.csv',\n",
    "                  header = True, index = False)\n",
    "\n",
    "# 00. Score of 0.12868\n",
    "# 01. Change from 25 max models to 1000. Score of 0.12792\n",
    "# 02. Sorting leaderboard by rmse as the main metric on h2o training. Score of 0.12792 made the same.\n",
    "# 02. Gonna make models for 30 min instead doing 1000 models. No improvement 0.13452\n",
    "# 02. We're going with 10.000 models. Score of 0.12970... no improving\n",
    "# 03. Trying with xgboost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c31df387a82a5100d8b8a1c9ab66134570f5e1392e7f0a8a822f81fc8c1365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
